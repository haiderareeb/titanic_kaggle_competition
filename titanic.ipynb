{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "1) predict the chances of surviving in a catastrophic event like titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #GEtting Titanic dataset from kaggle competition\n",
    "# import os\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "# import zipfile\n",
    "\n",
    "# # #setup the kaggle API key \n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = r\"C:\\Users\\haide\\OneDrive\\Desktop\\api's\\kaggle.json\"\n",
    "# api = KaggleApi()\n",
    "# api.authenticate()\n",
    "\n",
    "# # #competition dataset identifier\n",
    "# competition_name = 'titanic'\n",
    "# path='./titanic_dataset'\n",
    "# # #Fetch dataset from the Titanic Competition\n",
    "# api.competition_download_files(competition_name,path=path)\n",
    "\n",
    "# # Unzip the downloaded files manually\n",
    "# with zipfile.ZipFile(os.path.join(path, 'titanic.zip'), 'r') as zip_ref:\n",
    "#     zip_ref.extractall(path)\n",
    "\n",
    "\n",
    "# print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('./titanic_dataset/titanic_train.csv')\n",
    "y = pd.DataFrame(X['survived'])\n",
    "X = X.drop(['survived'],axis=1)\n",
    "X_test = pd.read_csv('./titanic_dataset/titanic_test.csv')\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (680, 14)\n",
      "y_train:  (680, 1)\n",
      "X_val:  (170, 14)\n",
      "y_val:  (170, 1)\n",
      "X_test:  (459, 14)\n"
     ]
    }
   ],
   "source": [
    "#check dims\n",
    "print('X_train: ',X_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 680 entries, 332 to 102\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  680 non-null    int64  \n",
      " 1   pclass        680 non-null    int64  \n",
      " 2   name          680 non-null    object \n",
      " 3   sex           680 non-null    object \n",
      " 4   age           539 non-null    float64\n",
      " 5   sibsp         680 non-null    int64  \n",
      " 6   parch         680 non-null    int64  \n",
      " 7   ticket        680 non-null    object \n",
      " 8   fare          679 non-null    float64\n",
      " 9   cabin         155 non-null    object \n",
      " 10  embarked      680 non-null    object \n",
      " 11  boat          242 non-null    object \n",
      " 12  body          60 non-null     float64\n",
      " 13  home.dest     379 non-null    object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 79.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# checking features usablility and filtering out the good one's\n",
    "X_train.info()\n",
    "X_train['name'].describe() #rremove\n",
    "#name feature is unique for each instance hence is not useful\n",
    "X_train['ticket'].describe() #remoce\n",
    "#ticket id isn't useful cause it's unique for almost instance\n",
    "X_train['cabin'].head() #frequency encoding and remove\n",
    "# cabin id can be used with some preprocessing(we can know which deck side had more chances of surviving)\n",
    "X_train['embarked'].describe() #frequency encoding and remove\n",
    "# embarked can encoded and stored\n",
    "X_train['boat'].describe() #frequency encoding and remove\n",
    "#only 242 people were issued boat at evacuation. it will be useful.\n",
    "X_train['body'].describe() \n",
    "# only 60 people body were found. we will know which bodies(not surviving one's) were found with what similarities.\n",
    "X_train['home.dest'].describe() #frequency encoding and remove\n",
    "#we can use home.dest to keep track of allocations or lifestyle and some patterns between people\n",
    "X_train['sex'].describe()\n",
    "#useful\n",
    "X_train['age'].describe()\n",
    "#useful\n",
    "X_train['sibsp'].describe()\n",
    "#useful\n",
    "X_train['parch'].describe()\n",
    "#well almost all values in parch are 0. but let's keep it for now\n",
    "X_train['fare'].describe()\n",
    "#useful for patterns of variation within classes.\n",
    "X_train['pclass'].describe()\n",
    "#useful\n",
    "\n",
    "#removing  cols name and ticket\n",
    "X_train = X_train.drop(['name','ticket'],axis=1)\n",
    "X_val = X_val.drop(['name','ticket'],axis=1)\n",
    "X_test = X_test.drop(['name','ticket'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (680, 12)\n",
      "y_train:  (680, 1)\n",
      "X_val:  (170, 12)\n",
      "y_val:  (170, 1)\n",
      "X_test:  (459, 12)\n"
     ]
    }
   ],
   "source": [
    "#check dims\n",
    "print('X_train: ',X_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=['int64','float64']).columns\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#for cat_cols\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_train[cat_cols] =  mode_imputer.fit_transform(X_train[cat_cols])\n",
    "X_val[cat_cols] = mode_imputer.transform(X_val[cat_cols])\n",
    "X_test[cat_cols] = mode_imputer.transform(X_test[cat_cols])\n",
    "\n",
    "#for num_cols\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "X_train[num_cols] = mean_imputer.fit_transform(X_train[num_cols])\n",
    "X_val[num_cols] = mean_imputer.transform(X_val[num_cols])\n",
    "X_test[num_cols] = mean_imputer.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex          0\n",
      "cabin        0\n",
      "embarked     0\n",
      "boat         0\n",
      "home.dest    0\n",
      "dtype: int64\n",
      "sex          0\n",
      "cabin        0\n",
      "embarked     0\n",
      "boat         0\n",
      "home.dest    0\n",
      "dtype: int64\n",
      "sex          0\n",
      "cabin        0\n",
      "embarked     0\n",
      "boat         0\n",
      "home.dest    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(X_train[cat_cols].isnull().sum())\n",
    "print(X_test[cat_cols].isna().sum())\n",
    "print(X_val[cat_cols].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (680, 12)\n",
      "y_train:  (680, 1)\n",
      "X_val:  (170, 12)\n",
      "y_val:  (170, 1)\n",
      "X_test:  (459, 12)\n"
     ]
    }
   ],
   "source": [
    "#check dims\n",
    "print('X_train: ',X_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding cat cols:\n",
    "import numpy as np\n",
    "\n",
    "for col in cat_cols:\n",
    "    mapping = X_train[col].value_counts()\n",
    "    \n",
    "    # Apply mapping to train, test, and validation sets\n",
    "    X_train[col + '_encoded'] = X_train[col].map(mapping).fillna(-1)  # Default missing categories to -1\n",
    "    X_test[col + '_encoded'] = X_test[col].map(mapping).fillna(-1)    # Default missing categories to -1\n",
    "    X_val[col + '_encoded'] = X_val[col].map(mapping).fillna(-1)      # Default missing categories to -1\n",
    "\n",
    "\n",
    "\n",
    "#ohe\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "train_encoded_cols = encoder.fit_transform(X_train[['sex']])\n",
    "test_encoded_cols = encoder.transform(X_test[['sex']])\n",
    "val_encoded_cols = encoder.transform(X_val[['sex']])\n",
    "\n",
    "X_train_ohe = pd.DataFrame(train_encoded_cols,columns=encoder.get_feature_names_out(['sex']))\n",
    "X_test_ohe = pd.DataFrame(test_encoded_cols,columns=encoder.get_feature_names_out(['sex']))\n",
    "X_val_ohe = pd.DataFrame(val_encoded_cols,columns=encoder.get_feature_names_out(['sex']))\n",
    "\n",
    "X_train = pd.concat([X_train,X_train_ohe],axis=1)\n",
    "X_test = pd.concat([X_test,X_test_ohe],axis=1)\n",
    "X_val = pd.concat([X_val,X_val_ohe],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing the sex ohe cols\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "X_train[['sex_female','sex_male']] = mean_imputer.fit_transform(X_train[['sex_female','sex_male']])\n",
    "X_val[['sex_female','sex_male']] = mean_imputer.transform(X_val[['sex_female','sex_male']])\n",
    "X_test[['sex_female','sex_male']] = mean_imputer.transform(X_test[['sex_female','sex_male']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (810, 19)\n",
      "y_train:  (680, 1)\n",
      "X_val:  (307, 19)\n",
      "y_val:  (170, 1)\n",
      "X_test:  (459, 19)\n"
     ]
    }
   ],
   "source": [
    "#check dims\n",
    "print('X_train: ',X_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex          130\n",
      "cabin        130\n",
      "embarked     130\n",
      "boat         130\n",
      "home.dest    130\n",
      "dtype: int64\n",
      "sex          0\n",
      "cabin        0\n",
      "embarked     0\n",
      "boat         0\n",
      "home.dest    0\n",
      "dtype: int64\n",
      "sex          137\n",
      "cabin        137\n",
      "embarked     137\n",
      "boat         137\n",
      "home.dest    137\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(X_train[cat_cols].isnull().sum())\n",
    "print(X_test[cat_cols].isna().sum())\n",
    "print(X_val[cat_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (680, 19)\n",
      "y_train:  (680, 1)\n",
      "X_val:  (170, 19)\n",
      "y_val:  (170, 1)\n",
      "X_test:  (459, 19)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values only in categorical columns\n",
    "X_train = X_train.dropna(subset=cat_cols)\n",
    "X_test = X_test.dropna(subset=cat_cols)\n",
    "X_val = X_val.dropna(subset=cat_cols)\n",
    "\n",
    "\n",
    "#check dims\n",
    "#check dims\n",
    "print('X_train: ',X_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop original cols\n",
    "X_train = X_train.drop(cat_cols,axis=1)\n",
    "X_test = X_test.drop(cat_cols,axis=1)\n",
    "X_val = X_val.drop(cat_cols,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (680, 14)\n",
      "y_train:  (680, 1)\n",
      "X_val:  (170, 14)\n",
      "y_val:  (170, 1)\n",
      "X_test:  (459, 14)\n"
     ]
    }
   ],
   "source": [
    "#check dims\n",
    "print('X_train: ',X_train.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print(\"X_val: \",X_val.shape)\n",
    "print(\"y_val: \",y_val.shape)\n",
    "print(\"X_test: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((680, 14), (680,))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dimensions\n",
    "y_train = y_train.to_numpy().ravel()\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn1.predict(X_train)\n",
    "preds\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_preds = cross_val_predict(knn1,X_train,y_train,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score:  0.9279661016949152\n",
      "recall score:  0.8938775510204081\n",
      "confusion matrix:  [[418  17]\n",
      " [ 26 219]]\n"
     ]
    }
   ],
   "source": [
    "print('precision_score: ',precision_score(y_train,y_train_preds))\n",
    "print('recall score: ',recall_score(y_train,y_train_preds))\n",
    "print('confusion matrix: ',confusion_matrix(y_train,y_train_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights:\n",
    "1) model prediction are bad. let's try finetuning using gridsearchcv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best Parameters:  {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Best Estimators:  KNeighborsClassifier(metric='euclidean', n_neighbors=3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid={\n",
    "    'n_neighbors':[3,5,7,10],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'metric': ['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "knn2  =KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn2,param_grid,cv=3,\n",
    "                           verbose=1,n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9632352941176471\n"
     ]
    }
   ],
   "source": [
    "knn3  = grid_search.best_estimator_\n",
    "knn3preds = knn3.predict(X_train)\n",
    "\n",
    "print('accuracy_score: ', accuracy_score(y_train,knn3preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6397058823529411\n"
     ]
    }
   ],
   "source": [
    "# comparing with a dumb model that predicts just 0\n",
    "y_train_no_preds = np.zeros_like(y_train)\n",
    "\n",
    "\n",
    "print('accuracy_score: ',accuracy_score(y_train,y_train_no_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9823529411764705\n"
     ]
    }
   ],
   "source": [
    "# score on val set\n",
    "knn3  = grid_search.best_estimator_\n",
    "knn3preds = knn3.predict(X_val)\n",
    "\n",
    "print('accuracy_score: ', accuracy_score(y_val,knn3preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds of test set\n",
    "knn3  = grid_search.best_estimator_\n",
    "knn3preds_test = knn3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "1) Our model is performing much better than a base line model\n",
    "2) best model knn3 with 97-98% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_kaggle_submission(test_data, predictions, output_filename='submission.csv'):\n",
    "    \"\"\"\n",
    "    Generates a Kaggle submission CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    test_data (DataFrame): The test data that contains the 'Id' column.\n",
    "    predictions (array-like): The predicted labels or values.\n",
    "    output_filename (str): The name of the output CSV file (default is 'submission.csv').\n",
    "    \n",
    "    Returns:\n",
    "    None: Saves the submission CSV file in the current directory.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame with the 'Id' column and predictions\n",
    "    submission_df = pd.DataFrame({\n",
    "        'passenger_id': test_data['passenger_id'].astype(np.int32),  # Ensure your test data has an 'Id' column\n",
    "        'Survived': predictions  # Replace with the correct name if needed\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    submission_df.to_csv(output_filename, index=False)\n",
    "    print(f\"Submission file '{output_filename}' created successfully!\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have the test data (test_data) and predictions (y_pred)\n",
    "# create_kaggle_submission(test_data, y_pred)\n",
    "create_kaggle_submission(X_test,knn3preds_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "1) The score on test set was 0.962."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
